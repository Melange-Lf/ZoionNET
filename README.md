
<div align="center">

# ZoionNet


*Low-Power Intrusion Detection Using Acoustic-based Deep Learning Classifier for Cellular Remote Sensing System*

*Originally Meant for Animal Intrusion Detection in Methagiri Forest*
</div>

--------

This Project is an extenion of the of submission (under the same name) to the [IEEE Comsoc Student competiion 2024](https://www.comsoc.org/membership/ieee-comsoc-student-competition/winners), where the submission earned an honorary mention (ie top 15 worldwide).

This repo aims to provide a more powerful and refined approach over the original submission on the same problem, with use of other architecutres like AST, and CRNN and more advance edge devices.

## Current Methodlogy

The audio data obtained from various sources will be preprocessed into mel-spectrograms. With time bins being dependent on the dataset, frquency bins will be fixed at 128. The entire dataset will be then normalized.


The detection model will operate during the "dormant" state of the sensor, all around the
 clock. The classification model will operate during the "active" state when there is a high
 chance of an sound event occurance as suggested by the detection model.


 An exponential moving average is maintained over the previous detection model's
 output, if it passes a certain threshold, the sensor switches to active mode. Here too
 another exponential moving average is maintained over the classification model's 'none'
 class, once its average exceeds a threshold, the model switches back to a dormant
 state.


 As the detection model is lightweight, it is bound to produce false values, the
 exponential moving average is used to decrease the impact of occasional false outputs
 on the state switch. At the same time the detection model uses much less power when
 run constantly, than its classification counterpart.
 Hence the two-model approach aims to bring down energy costs while still maintaining
 the sensor accuracy

The current model architecuture to be used for both the models is the CRNN architecutre, which is lightweight while still being able to learn time dependent features, and being able to process frequency bins based on cnn architecture.

For improving the convergence of the models, we will train them using information distilled by the more robust Audio Spectrogram Transformer model, using soft labels generated by the model trained on the same datasets.

To enable real-time inference on low-power embedded systems, the models will be optimized using quantization. This significantly reduced their computational and memory footprint without sacrificing accuracy.



## Legacy performace

For full details over the Legacy submission please refer to [Methodology Abstract](https://github.com/Melange-Lf/ZoionNET/blob/main/legacy_files/ZoionNET_Comsoc_submission.pdf)

The orignally implemented models based on the YOLO architecture were trained on our own custom dataset consisting of sound classes of animals native to the Methagiri forest (Cheetah, Elephants and Monkeys).

The detection model was able to reach around 95% accuracy, while the classfication model was able to reach 90% accuracy.


## Files and Folders

- `crnn`: contains the literature and the subsequent implementation of the CRNN model
- `AST`: contains the literature and implementation of the AST model
- `legacy_files`: Contains methodology abstract and experimentation submitted to IEEE, based on the previous implementation
- `melspec.ipynb`: Contains code for loading audio files and converting them to mel log spectrograms

## Prerequisites

The required libaries can be installed using the requirements file
NOTE: These will be brought down once experimentation is reached

Currenlty the Prerequisites include:

- Numpy
- scipy
- ipython
- Pytorch
- Torchinfo
- Torchvision
- Pandas
- PIL
- Librosa


```bash
pip install -r requirements.txt
```

### Current Progress/ To be done

- Models for AST and CRNN ready
- Preprocessing scripts ready
- Soft Labels for ESC-50 dataset ready for benchmarking

---------------------------------------------------------

- Preparation for the Balanced Audioset dataset pending
- Current limitations is a reliable source for the dataset along with hardware resources to process the entire dataset
